# Explainable AI (XAI) Methods for Reinforcement of Object Recognition and Localization in the Wild Egocentric Videos

In this study, we applied three explainers to analyze features contributing to object recognition and localization by YOLOv8. We evaluated these explainers against ground truth data, using gaze fixation density maps, and computed the Pearson correlation coefficient. Our findings show that the FEM method aligns best with the ground truth

![Image](https://github.com/user-attachments/assets/74f2ba62-704e-4209-805a-1d2e742d8929)

## PCC 

<img width="698" alt="Image" src="https://github.com/user-attachments/assets/29e9ff35-a5a9-4966-8338-3a1d12600dd0" />

## Running the Project

Each folder comes with its own detailed README explaining the steps to run the project. Please ensure you follow the instructions in each folder for the respective task:

## Future Work

This project is part of ongoing research to refine object recognition and localization in dynamic, real-world settings. Future improvements include:
- Enhancing the integration of XAI methods to improve model accuracy and decision-making.
- Exploring new explainability techniques for better model transparency and validation.



## Dependencies

The following libraries are required to run the project:

- Python 3.x
- PyTorch
- OpenCV
- Matplotlib
- NumPy

To install dependencies, run:

```bash
pip install -r requirements.txt
