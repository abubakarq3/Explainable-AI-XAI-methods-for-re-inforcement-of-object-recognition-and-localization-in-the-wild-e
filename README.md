# Explainable AI (XAI) Methods for Reinforcement of Object Recognition and Localization in the Wild Egocentric Videos

In this study, we applied three explainers to analyze features contributing to object recognition and localization by YOLOv8. We evaluated these explainers against ground truth data, using gaze fixation density maps, and computed the Pearson correlation coefficient. Our findings show that the FEM method aligns best with the ground truth

![Image](https://github.com/user-attachments/assets/74f2ba62-704e-4209-805a-1d2e742d8929)

## PCC 

<img width="698" alt="Image" src="https://github.com/user-attachments/assets/29e9ff35-a5a9-4966-8338-3a1d12600dd0" />

## Running the Project

Each folder comes with its own detailed README explaining the steps to run the project. Please ensure you follow the instructions in each folder for the respective task:

## Future Work

This project is part of ongoing research. Future improvements include:
- To further refine this approach and explore additional methods for verifying and leveraging the explainers to improve model accuracy and reliability.

## Dependencies

The following libraries are required to run the project:

- Python 3.x
- PyTorch
- OpenCV
- Matplotlib
- NumPy

To install dependencies, run:

```bash
pip install -r requirements.txt
